{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the MNIST dataset from keras.datasets and load it in x train, y train, x test, y test variables.\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#check the train and test shape.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#In oder to be able using the sigmoid activation function, normalize x train and x test according to the maximum and minimum elements of image set, for instance check x train[0].\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some images to see your normalization results.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_train[1], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_train[2], cmap='gray')\n",
    "plt.show()\n",
    "# Notice The Encoder generally uses a series of Dense and/or Convolutional layers to encode an \n",
    "# image into a fixed length vector that represents the image acompact form, while the Decoder \n",
    "# uses Dense and/or Convolutional layers toconvert the latent representation vector back into \n",
    "# that same image or anothermodified image (see Figure 1).\n",
    "\n",
    "# Latent size is the size of the latent space: the vector holding the information\n",
    "# after compression. This value is a crucial hyperparameter. If this value is too\n",
    "# small, there won’t be enough data for reconstruction and if the value is too\n",
    "# large, overfitting can occur."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s define the LATENT SIZE = 32. Create an encoder model consists of a series  \n",
    "# of dense layers, each layer is followed by a Dropout and a ReLU layer.\n",
    "Latent_Size = 32\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import backend as K\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "x = Dense(512)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# Do not forget to add a final Dense layer for generating an output of LATENT SIZE.\n",
    "encoded = Dense(Latent_Size)(x)\n",
    "encoder = Model(input_img, encoded)\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
