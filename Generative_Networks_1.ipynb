{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the MNIST dataset from keras.datasets and load it in x train, y train, x test, y test variables.\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#check the train and test shape.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#In oder to be able using the sigmoid activation function, normalize x train and x test according to the maximum and minimum elements of image set, for instance check x train[0].\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some images to see your normalization results.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_train[1], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(X_train[2], cmap='gray')\n",
    "plt.show()\n",
    "# Notice The Encoder generally uses a series of Dense and/or Convolutional layers to encode an \n",
    "# image into a fixed length vector that represents the image acompact form, while the Decoder \n",
    "# uses Dense and/or Convolutional layers toconvert the latent representation vector back into \n",
    "# that same image or anothermodified image (see Figure 1).\n",
    "\n",
    "# Latent size is the size of the latent space: the vector holding the information\n",
    "# after compression. This value is a crucial hyperparameter. If this value is too\n",
    "# small, there won’t be enough data for reconstruction and if the value is too\n",
    "# large, overfitting can occur."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s define the LATENT SIZE = 32. Create an encoder model consists of a series  \n",
    "# of dense layers, each layer is followed by a Dropout and a ReLU layer.\n",
    "Latent_Size = 32\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import backend as K\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "x = Dense(512)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# Do not forget to add a final Dense layer for generating an output of LATENT SIZE.\n",
    "encoded = Dense(Latent_Size)(x)\n",
    "encoder = Model(input_img, encoded)\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exe. 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decoder model namely decoder. The decoder is essentially\n",
    "the same as the encoder but in reverse.\n",
    "Dense, ReLU, Dropout, Dense, ReLU, Dropout, Dense, ReLU,\n",
    "Dropout, Dense, ReLU, Dropout, Dense, Acivation, Reshape\n",
    "Notice that the Dense layers have the same size in the reverse order as the\n",
    "encoder, and the final dense layer is a layer of size 28 × 28 = 784 that should\n",
    "be reshaped to 28 × 28 for reproducing the same image input. The sigmoid\n",
    "activation function output values in the range [0, 1] to fit with the input scaled\n",
    "image data (use the Reshape from keras.layers).\n",
    "To create the full model, the Keras Functional API must be used. The\n",
    "Functional API allows us to string together multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decoder model namely decoder. The decoder is essentially\n",
    "# the same as the encoder but in reverse.\n",
    "# Dense, ReLU, Dropout, Dense, ReLU, Dropout, Dense, ReLU,\n",
    "# Dropout, Dense, ReLU, Dropout, Dense, Acivation, Reshape\n",
    "decoder = Model(encoded, Flatten()(Dense(64)(LeakyReLU()(Dropout(0.3)(Dense(128)(LeakyReLU()(Dropout(0.3)(Dense(256)(LeakyReLU()(Dropout(0.3)(Dense(512)(LeakyReLU()(Dropout(0.3)(Dense(784)(LeakyReLU()(Dropout(0.3)(encoded)))))))))))))))))\n",
    "decoder.summary()\n",
    "\n",
    "# Notice that the Dense layers have the same size in the reverse order as the\n",
    "# encoder, and the final dense layer is a layer of size 28 × 28 = 784 that should\n",
    "# be reshaped to 28 × 28 for reproducing the same image input. The sigmoid\n",
    "# activation function output values in the range [0, 1] to fit with the input scaled\n",
    "# image data (use the Reshape from keras.layers).\n",
    "\n",
    "# To create the full model, the Keras Functional API must be used. The\n",
    "# Functional API allows us to string together multiple models.\n",
    "from tensorflow.keras.layers import Input\n",
    "img = Input(shape = (28,28))\n",
    "\n",
    "# This will create a placeholder tensor which we can feed into each network to get\n",
    "# the output of the whole model\n",
    "latent_vector = encoder ( img )\n",
    "output = decoder ( latent_vector )\n",
    "\n",
    "# The best part about the Keras Functional API is how readable it is. The Keras\n",
    "# Functional API allows you to call models directly onto tensors and get the\n",
    "# output from that tensor. By calling the encoder model onto the img tensor, we\n",
    "# get the latent vector. The same can be done  with the decoder model onto \n",
    "# the latent vector which gives us the output.\n",
    "model = Model(inputs = img, outputs = output)\n",
    "model.compile(\"nadam\", loss = \"binary_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# ’nadam’: Nesterov Adam optimizer. Much like Adam is essentially RMSprop\n",
    "# with momentum, Nadam is RMSprop with Nesterov momentum. To create the\n",
    "# model itself, we use the Model class and define what the inputs and outputs of\n",
    "# the model are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
